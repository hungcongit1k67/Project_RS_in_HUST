{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-28T13:31:58.146305Z",
     "iopub.status.busy": "2025-09-28T13:31:58.146031Z",
     "iopub.status.idle": "2025-09-28T13:32:00.684184Z",
     "shell.execute_reply": "2025-09-28T13:32:00.682927Z",
     "shell.execute_reply.started": "2025-09-28T13:31:58.146283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\sample.txt\n",
      "data\\test.txt\n",
      "data\\train.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:00.686873Z",
     "iopub.status.busy": "2025-09-28T13:32:00.686333Z",
     "iopub.status.idle": "2025-09-28T13:32:01.297474Z",
     "shell.execute_reply": "2025-09-28T13:32:01.296370Z",
     "shell.execute_reply.started": "2025-09-28T13:32:00.686839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  movieid  rating\n",
      "0       1        1       5\n",
      "1       1        2       3\n",
      "2       1        3       4\n",
      "3       1        4       3\n",
      "4       1        5       3\n",
      "userid     int64\n",
      "movieid    int64\n",
      "rating     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "path = \"data/train.txt\"  # đổi nếu cần\n",
    "\n",
    "rows = []\n",
    "with open(path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        nums = re.findall(r\"-?\\d+\", line)\n",
    "        if len(nums) >= 3:\n",
    "            rows.append([int(nums[0]), int(nums[1]), int(nums[2])])\n",
    "\n",
    "df_train = pd.DataFrame(rows, columns=[\"userid\", \"movieid\", \"rating\"])\n",
    "print(df_train.head())\n",
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:01.298851Z",
     "iopub.status.busy": "2025-09-28T13:32:01.298568Z",
     "iopub.status.idle": "2025-09-28T13:32:01.462878Z",
     "shell.execute_reply": "2025-09-28T13:32:01.461224Z",
     "shell.execute_reply.started": "2025-09-28T13:32:01.298827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  movieid\n",
      "0       1       20\n",
      "1       1       33\n",
      "2       1       61\n",
      "3       1      117\n",
      "4       1      155\n",
      "userid     int64\n",
      "movieid    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "path = \"data/test.txt\"  # đổi nếu cần\n",
    "\n",
    "rows = []\n",
    "with open(path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        nums = re.findall(r\"-?\\d+\", line)\n",
    "        if len(nums) >= 2:\n",
    "            rows.append([int(nums[0]), int(nums[1])])\n",
    "\n",
    "df_test = pd.DataFrame(rows, columns=[\"userid\", \"movieid\"])\n",
    "print(df_test.head())\n",
    "print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:01.464931Z",
     "iopub.status.busy": "2025-09-28T13:32:01.463917Z",
     "iopub.status.idle": "2025-09-28T13:32:07.231655Z",
     "shell.execute_reply": "2025-09-28T13:32:07.230523Z",
     "shell.execute_reply.started": "2025-09-28T13:32:01.464899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from typing import Sequence, List\n",
    "class NeuMF(nn.Module):\n",
    "    \"\"\"\n",
    "    NeuMF với one-hot embedding:\n",
    "      - User/Item -> one-hot (cố định) -> Linear chiếu sang latent (thay cho nn.Embedding)\n",
    "      - Nhánh GMF: element-wise product giữa 2 latent vector\n",
    "      - Nhánh MLP: concat 2 latent, qua nhiều Dense + ReLU (+ Dropout)\n",
    "      - Fusion: concat(GMF, MLP) -> Dropout -> (Dropout head) -> Linear(…, 1)\n",
    "\n",
    "    Tham số dropout:\n",
    "      - dropout_proj  : dropout ngay sau chiếu one-hot -> latent (cả GMF và MLP)\n",
    "      - dropout_hidden: dropout sau mỗi Dense của tháp MLP\n",
    "      - dropout_fusion: dropout sau khi concat GMF & MLP\n",
    "      - dropout_fc    : dropout ngay trước lớp Linear cuối cùng\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 k_gmf: int = 8,\n",
    "                 k_mlp: int = 32,\n",
    "                 mlp_layers=(64, 32, 16),\n",
    "                 dropout_hidden: float = 0.3,\n",
    "                 dropout_proj: float = 0.1,\n",
    "                 dropout_fusion: float = 0.2,\n",
    "                 dropout_fc: float = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # One-hot \"embeddings\": identity, freeze để dùng như one-hot lookup\n",
    "        self.oh_user = nn.Embedding.from_pretrained(torch.eye(num_users), freeze=True)\n",
    "        self.oh_item = nn.Embedding.from_pretrained(torch.eye(num_items), freeze=True)\n",
    "\n",
    "        # Chiếu one-hot -> latent (thay cho nn.Embedding)\n",
    "        self.gmf_user_proj = nn.Linear(num_users, k_gmf, bias=False)\n",
    "        self.gmf_item_proj = nn.Linear(num_items, k_gmf, bias=False)\n",
    "        self.mlp_user_proj = nn.Linear(num_users, k_mlp, bias=False)\n",
    "        self.mlp_item_proj = nn.Linear(num_items, k_mlp, bias=False)\n",
    "\n",
    "        # Dropout sau projection\n",
    "        self.do_proj_gmf_u = nn.Dropout(dropout_proj)\n",
    "        self.do_proj_gmf_i = nn.Dropout(dropout_proj)\n",
    "        self.do_proj_mlp_u = nn.Dropout(dropout_proj)\n",
    "        self.do_proj_mlp_i = nn.Dropout(dropout_proj)\n",
    "\n",
    "        # Tháp MLP: (Linear -> ReLU -> Dropout) * len(mlp_layers)\n",
    "        mlp = []\n",
    "        in_dim = k_mlp * 2\n",
    "        for units in mlp_layers:\n",
    "            mlp += [\n",
    "                nn.Linear(in_dim, units),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_hidden),\n",
    "            ]\n",
    "            in_dim = units\n",
    "        self.mlp_layers = nn.Sequential(*mlp)\n",
    "\n",
    "        # Dropout sau khi concat(GMF, MLP)\n",
    "        self.do_fusion = nn.Dropout(dropout_fusion)\n",
    "\n",
    "        # Head: Dropout trước fc\n",
    "        fusion_dim = k_gmf + (mlp_layers[-1] if mlp_layers else k_mlp * 2)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dropout_fc),\n",
    "            nn.Linear(fusion_dim, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Xavier cho các Linear\n",
    "        for m in [self.gmf_user_proj, self.gmf_item_proj, self.mlp_user_proj, self.mlp_item_proj]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        for m in self.mlp_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        lin = self.head[1]  # Linear cuối\n",
    "        nn.init.xavier_uniform_(lin.weight)\n",
    "        nn.init.zeros_(lin.bias)\n",
    "\n",
    "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        users: LongTensor shape (B,)\n",
    "        items: LongTensor shape (B,)\n",
    "        return: FloatTensor shape (B,)  — điểm số (rating dự đoán)\n",
    "        \"\"\"\n",
    "        # One-hot vectors (0/1)\n",
    "        u_oh = self.oh_user(users)   # (B, num_users)\n",
    "        i_oh = self.oh_item(items)   # (B, num_items)\n",
    "\n",
    "        # ----- GMF path -----\n",
    "        gu = self.gmf_user_proj(u_oh)      # (B, k_gmf)\n",
    "        gi = self.gmf_item_proj(i_oh)      # (B, k_gmf)\n",
    "        gu = self.do_proj_gmf_u(gu)\n",
    "        gi = self.do_proj_gmf_i(gi)\n",
    "        gmf = gu * gi                      # element-wise\n",
    "\n",
    "        # ----- MLP path -----\n",
    "        mu = self.mlp_user_proj(u_oh)      # (B, k_mlp)\n",
    "        mi = self.mlp_item_proj(i_oh)      # (B, k_mlp)\n",
    "        mu = self.do_proj_mlp_u(mu)\n",
    "        mi = self.do_proj_mlp_i(mi)\n",
    "        x = torch.cat([mu, mi], dim=-1)    # (B, 2*k_mlp)\n",
    "        x = self.mlp_layers(x)\n",
    "\n",
    "        # ----- Fusion + head -----\n",
    "        z = torch.cat([gmf, x], dim=-1)\n",
    "        z = self.do_fusion(z)\n",
    "        score = self.head(z).squeeze(-1)   # (B,)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:07.233163Z",
     "iopub.status.busy": "2025-09-28T13:32:07.232734Z",
     "iopub.status.idle": "2025-09-28T13:32:07.246490Z",
     "shell.execute_reply": "2025-09-28T13:32:07.245356Z",
     "shell.execute_reply.started": "2025-09-28T13:32:07.233139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from typing import Sequence, List\n",
    "\n",
    "class DMF(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Matrix Factorization (học trực tiếp A):\n",
    "      - A: (num_users, num_items) là tham số học được.\n",
    "      - forward(users, items):\n",
    "          + user vector = A[u, :]  (1 hàng)\n",
    "          + item vector = A[:, v]  (1 cột)\n",
    "          + qua MLP riêng -> L2-normalize -> cosine -> map [1,5]\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 d1: int = 64,                    # (không dùng ở bản này)\n",
    "                 hidden: Sequence[int] = (64, 32, 16),\n",
    "                 dropout: float = 0.2,\n",
    "                 use_bn: bool = False):\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "\n",
    "        # Ma trận A học trực tiếp (khởi tạo nhỏ quanh 0 để điểm ~3 sau khi map)\n",
    "        self.A = nn.Parameter(torch.randn(num_users, num_items) * 0.01)\n",
    "\n",
    "        # Tower MLP: user nhận vectơ kích thước num_items; item nhận vectơ kích thước num_users\n",
    "        def make_mlp(in_dim):\n",
    "            layers = []\n",
    "            last = in_dim\n",
    "            for h in hidden:\n",
    "                layers += [nn.Linear(last, h)]\n",
    "                if use_bn:\n",
    "                    layers += [nn.BatchNorm1d(h)]\n",
    "                layers += [nn.ReLU(inplace=True), nn.Dropout(dropout)]\n",
    "                last = h\n",
    "            return nn.Sequential(*layers), last\n",
    "\n",
    "        self.user_mlp, Du = make_mlp(num_items)\n",
    "        self.item_mlp, Dv = make_mlp(num_users)\n",
    "        assert Du == Dv, \"Hai tower phải có cùng output dim để tính cosine.\"\n",
    "        self.out_dim = Du\n",
    "        self.head = nn.Linear(self.out_dim * 2, 1)   # học cách ghép pu & qv -> score\n",
    "        nn.init.xavier_uniform_(self.head.weight)\n",
    "        nn.init.zeros_(self.head.bias)\n",
    "        # Khởi tạo tuyến tính\n",
    "        for m in list(self.user_mlp.modules()) + list(self.item_mlp.modules()):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    # --------------------------- forward (giống Neu) ---------------------------\n",
    "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        users/items: LongTensor (B,)\n",
    "        return: FloatTensor (B,) in [1, 5]\n",
    "        \"\"\"\n",
    "        # Lấy hàng/cột từ A\n",
    "        rows = self.A[users, :]                   # (B, num_items)\n",
    "        cols = self.A[:, items].transpose(0, 1)   # (B, num_users)\n",
    "    \n",
    "        # Qua MLP hai nhánh\n",
    "        pu = self.user_mlp(rows) if len(self.user_mlp) else rows   # (B, D)\n",
    "        qv = self.item_mlp(cols) if len(self.item_mlp) else cols   # (B, D)\n",
    "    \n",
    "        # (tuỳ chọn) normalize nhẹ, có thể bỏ nếu muốn để Linear tự học\n",
    "        # pu = F.normalize(pu, p=2, dim=-1)\n",
    "        # qv = F.normalize(qv, p=2, dim=-1)\n",
    "    \n",
    "        # Ghép và cho qua Linear head\n",
    "        z = torch.cat([pu, qv], dim=-1)           # (B, 2D)\n",
    "        s = self.head(z).squeeze(-1)              # (B,)\n",
    "    \n",
    "        # Ràng buộc đầu ra về [1, 5] bằng sigmoid thay vì clamp\n",
    "        \n",
    "        return s\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:07.247914Z",
     "iopub.status.busy": "2025-09-28T13:32:07.247584Z",
     "iopub.status.idle": "2025-09-28T13:32:07.282244Z",
     "shell.execute_reply": "2025-09-28T13:32:07.280962Z",
     "shell.execute_reply.started": "2025-09-28T13:32:07.247890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Sequence, Tuple\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    LightGCN tối giản cho implicit CF.\n",
    "    - E^(0) = concat([E_user, E_item]) với shape [(M+N), d] (user trước, item sau).\n",
    "    - Propagation: E^(k+1) = A_tilde @ E^(k), A_tilde = D^{-1/2} A D^{-1/2}.\n",
    "    - Layer-combine: E_final = sum_{k=0..K} alpha_k * E^(k), mặc định alpha_k = 1/(K+1).\n",
    "    - Score(u,i) = <e_u, e_i>.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        embedding_dim: int = 64,\n",
    "        num_layers: int = 3,\n",
    "        edges: Optional[torch.LongTensor] = None,   # shape [2, E], (user_id, item_id)\n",
    "        alpha: Optional[torch.Tensor] = None,       # (K+1,), nếu None -> uniform\n",
    "        device: Optional[torch.device] = None,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # E^(0): embedding riêng user & item\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "\n",
    "        # Alpha cho trộn tầng\n",
    "        no_edges = (edges is None) or (edges.numel() == 0)\n",
    "        if alpha is None:\n",
    "            if no_edges:\n",
    "                alpha = torch.zeros(num_layers + 1, dtype=dtype); alpha[0] = 1.0\n",
    "            else:\n",
    "                alpha = torch.full((num_layers + 1,), 1.0/(num_layers + 1), dtype=dtype)\n",
    "        else:\n",
    "            assert alpha.numel() == num_layers + 1, \"alpha phải có K+1 phần tử\"\n",
    "            alpha = alpha.to(dtype=dtype)\n",
    "        self.register_buffer(\"alpha\", alpha)\n",
    "\n",
    "        # A_tilde (sparse)\n",
    "        if no_edges:\n",
    "            num_nodes = num_users + num_items\n",
    "            A_tilde = torch.sparse_coo_tensor(\n",
    "                torch.zeros((2, 0), dtype=torch.long),\n",
    "                torch.tensor([], dtype=dtype),\n",
    "                (num_nodes, num_nodes),\n",
    "                device=device,\n",
    "                dtype=dtype\n",
    "            ).coalesce()\n",
    "        else:\n",
    "            A_tilde = self._build_norm_adj(edges, device=device, dtype=dtype)\n",
    "\n",
    "        # Lưu buffer chỉ số & giá trị để tái tạo nhanh mỗi lần propagate\n",
    "        self.register_buffer(\"A_tilde_indices\", A_tilde.indices())\n",
    "        self.register_buffer(\"A_tilde_values\",  A_tilde.values())\n",
    "        self.A_tilde_size = A_tilde.size()\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _build_norm_adj(\n",
    "        self,\n",
    "        edges: torch.LongTensor,\n",
    "        device: Optional[torch.device],\n",
    "        dtype: torch.dtype,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Xây A_tilde = D^{-1/2} A D^{-1/2} cho đồ thị hai phía (vô hướng).\"\"\"\n",
    "        M, N = self.num_users, self.num_items\n",
    "        if device is None:\n",
    "            device = edges.device\n",
    "\n",
    "        u = edges[0].to(torch.long)               # [E]\n",
    "        i = (edges[1].to(torch.long) + M)         # shift item id: [E] trong [M, M+N)\n",
    "\n",
    "        # cạnh vô hướng: (u,i) & (i,u)\n",
    "        src = torch.cat([u, i])\n",
    "        dst = torch.cat([i, u])\n",
    "        indices = torch.stack([src, dst], dim=0)  # [2, 2E]\n",
    "        values = torch.ones(indices.size(1), dtype=dtype, device=device)\n",
    "        num_nodes = M + N\n",
    "\n",
    "        A = torch.sparse_coo_tensor(indices, values, (num_nodes, num_nodes),\n",
    "                                    device=device, dtype=dtype).coalesce()\n",
    "\n",
    "        deg = torch.sparse.sum(A, dim=1).to_dense().clamp(min=1.0)  # tránh 0\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        row, col = A.indices()\n",
    "        norm_vals = deg_inv_sqrt[row] * A.values() * deg_inv_sqrt[col]\n",
    "        return torch.sparse_coo_tensor(A.indices(), norm_vals, A.size(),\n",
    "                                       device=device, dtype=dtype).coalesce()\n",
    "\n",
    "    def _E0(self) -> torch.Tensor:\n",
    "        \"\"\"E^(0) = concat([E_user, E_item]) với shape [(M+N), d].\"\"\"\n",
    "        return torch.cat([self.user_emb.weight, self.item_emb.weight], dim=0)\n",
    "\n",
    "    def _propagate(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Lan truyền K bước và trộn tầng. Trả về (E_user_final, E_item_final).\"\"\"\n",
    "        E0 = self._E0()\n",
    "        Es = [E0]\n",
    "\n",
    "        if self.A_tilde_values.numel() > 0:\n",
    "            A_tilde = torch.sparse_coo_tensor(\n",
    "                self.A_tilde_indices, self.A_tilde_values, self.A_tilde_size,\n",
    "                device=E0.device, dtype=E0.dtype\n",
    "            )\n",
    "            Ek = E0\n",
    "            for _ in range(self.num_layers):\n",
    "                Ek = torch.sparse.mm(A_tilde, Ek)\n",
    "                Es.append(Ek)\n",
    "        else:\n",
    "            # không cạnh → các tầng sau = 0, alpha[0]=1 ⇒ E_final = E0\n",
    "            for _ in range(self.num_layers):\n",
    "                Es.append(torch.zeros_like(E0))\n",
    "\n",
    "        E_final = torch.zeros_like(E0)\n",
    "        for k, Ek in enumerate(Es):\n",
    "            E_final = E_final + self.alpha[k] * Ek\n",
    "\n",
    "        return E_final[: self.num_users], E_final[self.num_users :]\n",
    "\n",
    "    # ---------- public API ----------\n",
    "    @torch.no_grad()\n",
    "    def get_all_embeddings(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Trả về (E_user_final [M,d], E_item_final [N,d]).\"\"\"\n",
    "        return self._propagate()\n",
    "\n",
    "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        users, items: LongTensor [B]\n",
    "        Trả về: scores [B] = <e_u, e_i>\n",
    "        \"\"\"\n",
    "        U, I = self._propagate()\n",
    "        eu = U[users]            # [B, d]\n",
    "        ei = I[items]            # [B, d]\n",
    "        return (eu * ei).sum(dim=1)\n",
    "\n",
    "    def bpr_loss(\n",
    "        self,\n",
    "        users: torch.Tensor,\n",
    "        pos_items: torch.Tensor,\n",
    "        neg_items: torch.Tensor,\n",
    "        l2_reg: float = 1e-4,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Pairwise BPR loss; regularize chỉ E^(0) như LightGCN gốc.\n",
    "        users, pos_items, neg_items: LongTensor [B]\n",
    "        \"\"\"\n",
    "        U, I = self._propagate()\n",
    "        eu = U[users]\n",
    "        ei = I[pos_items]\n",
    "        ej = I[neg_items]\n",
    "        y_pos = (eu * ei).sum(dim=1)\n",
    "        y_neg = (eu * ej).sum(dim=1)\n",
    "        loss = -torch.nn.functional.logsigmoid(y_pos - y_neg).mean()\n",
    "\n",
    "        # L2 chỉ trên E^(0)\n",
    "        reg = (\n",
    "            self.user_emb.weight.norm(p=2).pow(2)\n",
    "            + self.item_emb.weight.norm(p=2).pow(2)\n",
    "        ) / (self.num_users + self.num_items)\n",
    "\n",
    "        return loss + l2_reg * reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:33:24.114627Z",
     "iopub.status.busy": "2025-09-28T13:33:24.113221Z",
     "iopub.status.idle": "2025-09-28T13:33:32.275478Z",
     "shell.execute_reply": "2025-09-28T13:33:32.273918Z",
     "shell.execute_reply.started": "2025-09-28T13:33:24.114590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m    116\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR, weight_decay\u001b[38;5;241m=\u001b[39mWEIGHT_DECAY)\n\u001b[1;32m--> 118\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[0;32m    119\u001b[0m     optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    120\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrmse\u001b[39m(y_true, y_pred):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39msqrt(((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mTypeError\u001b[0m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "# NeuMF in PyTorch: GMF + MLP for rating regression + AdamW + LR scheduler + save \"Id,Score\"\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split   # <-- thêm import\n",
    "\n",
    "# ================== Hyperparams & configs ==================\n",
    "SEED = 42\n",
    "SUB_PATH   = \"output/submission.csv\"\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = 'cpu'\n",
    "K_GMF = 8\n",
    "K_MLP = 32\n",
    "MLP_LAYERS = (32, 16, 8)\n",
    "DROPOUT = 0.4\n",
    "LR = 1e-2\n",
    "EPOCHS = 100\n",
    "BATCH_TRAIN = 1024\n",
    "BATCH_TEST  = 1024\n",
    "VAL_RATIO = 0.2\n",
    "PATIENCE = 20\n",
    "WEIGHT_DECAY = 1e-4  # AdamW weight decay\n",
    "\n",
    "# ================== Assume df_train / df_test are ready ==================\n",
    "# df_train: userid,movieid,rating ; df_test: userid,movieid\n",
    "\n",
    "# ---- mapping ID -> index liên tục (từ cả train + test) ----\n",
    "all_users = pd.Index(pd.concat([df_train['userid'], df_test['userid']]).unique())\n",
    "all_items = pd.Index(pd.concat([df_train['movieid'], df_test['movieid']]).unique())\n",
    "user2idx = {u:i for i,u in enumerate(all_users)}\n",
    "item2idx = {m:i for i,m in enumerate(all_items)}\n",
    "num_users = len(user2idx); num_items = len(item2idx)\n",
    "\n",
    "df_train_idx = df_train.assign(\n",
    "    user_idx = df_train['userid'].map(user2idx).astype('int64'),\n",
    "    item_idx = df_train['movieid'].map(item2idx).astype('int64')\n",
    ")\n",
    "df_test_idx = df_test.assign(\n",
    "    user_idx = df_test['userid'].map(user2idx).astype('int64'),\n",
    "    item_idx = df_test['movieid'].map(item2idx).astype('int64')\n",
    ")\n",
    "\n",
    "min_r = float(df_train['rating'].min())\n",
    "max_r = float(df_train['rating'].max())\n",
    "global_mean = float(df_train['rating'].mean())\n",
    "seen_users = set(df_train['userid'].unique())\n",
    "seen_items = set(df_train['movieid'].unique())\n",
    "\n",
    "# ================== Dataset / DataLoader ==================\n",
    "class RatingsDS(Dataset):\n",
    "    def __init__(self, u, i, y=None):\n",
    "        self.u = torch.as_tensor(u, dtype=torch.long)\n",
    "        self.i = torch.as_tensor(i, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.as_tensor(y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.u)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.u[idx], self.i[idx]\n",
    "        return self.u[idx], self.i[idx], self.y[idx]\n",
    "\n",
    "train_full = RatingsDS(\n",
    "    df_train_idx['user_idx'].values,\n",
    "    df_train_idx['item_idx'].values,\n",
    "    df_train_idx['rating'].values,\n",
    ")\n",
    "\n",
    "all_idx = np.arange(len(df_train_idx))\n",
    "train_idx, val_idx = train_test_split(\n",
    "    all_idx,\n",
    "    test_size=VAL_RATIO,\n",
    "    random_state=SEED,\n",
    "    stratify=df_train_idx['rating']\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_ds = Subset(train_full, train_idx)\n",
    "val_ds   = Subset(train_full, val_idx)\n",
    "\n",
    "test_ds  = RatingsDS(df_test_idx['user_idx'].values, df_test_idx['item_idx'].values)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds, batch_size=max(512, BATCH_TRAIN), shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_TEST, shuffle=False)\n",
    "\n",
    "# ================== Model ==================\n",
    "df_tr = df_train.copy()\n",
    "\n",
    "# Nếu có rating và muốn lấy positive theo ngưỡng:\n",
    "if 'rating' in df_tr.columns:\n",
    "    df_tr = df_tr[df_tr['rating'] >= 3.0]   # hoặc >= 3.5, tuỳ bài\n",
    "\n",
    "# Map sang chỉ số liên tục\n",
    "df_tr['user_idx'] = df_tr['userid'].map(user2idx).astype('int64')\n",
    "df_tr['item_idx'] = df_tr['movieid'].map(item2idx).astype('int64')\n",
    "\n",
    "# Mỗi (user,item) một cạnh (LightGCN không cần multiple-edges)\n",
    "df_tr = df_tr.drop_duplicates(subset=['user_idx', 'item_idx'])\n",
    "\n",
    "u = torch.as_tensor(df_tr['user_idx'].values, dtype=torch.long)\n",
    "i = torch.as_tensor(df_tr['item_idx'].values, dtype=torch.long)\n",
    "edges = torch.stack([u, i], dim=0).to(device)   # shape [2, E]\n",
    "\n",
    "\n",
    "# model = NeuMF(num_users, num_items, K_GMF, K_MLP, MLP_LAYERS, DROPOUT).to(device)\n",
    "# model = DMF(num_users, num_items, d1=64, hidden=(64,32), dropout=0.3, use_bn=True).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "model = LightGCN(num_users, num_items, embedding_dim=64, num_layers=3, edges=edges.to(device)).to(device)\n",
    "# ================== Train ==================\n",
    "device = next(model.parameters()).device\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-6\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(((y_true - y_pred) ** 2).mean().item())\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def r2_torch(y_true: torch.Tensor, y_pred: torch.Tensor) -> float:\n",
    "    \"\"\"R^2 dùng sklearn.\"\"\"\n",
    "    return r2_score(y_true.detach().cpu().numpy(),\n",
    "                    y_pred.detach().cpu().numpy())\n",
    "\n",
    "best_val = float(\"inf\"); patience = PATIENCE; bad = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ----- train -----\n",
    "    model.train()\n",
    "    for u,i,y in tqdm(train_loader):\n",
    "        u,i,y = u.to(device), i.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        p = model(u,i)\n",
    "        loss = criterion(p, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ----- evaluate train -----\n",
    "    model.eval()\n",
    "    ys_tr, ps_tr = [], []\n",
    "    with torch.no_grad():\n",
    "        for u,i,y in train_loader:\n",
    "            u,i,y = u.to(device), i.to(device), y.to(device)\n",
    "            p = model(u,i)\n",
    "            ys_tr.append(y.cpu()); ps_tr.append(p.cpu())\n",
    "    y_tr = torch.cat(ys_tr); p_tr = torch.cat(ps_tr)\n",
    "    train_rmse = rmse(y_tr, p_tr)\n",
    "    train_r2   = r2_torch(y_tr, p_tr)\n",
    "\n",
    "    # ----- validate -----\n",
    "    ys_v, ps_v = [], []\n",
    "    with torch.no_grad():\n",
    "        for u,i,y in tqdm(val_loader):\n",
    "            u,i,y = u.to(device), i.to(device), y.to(device)\n",
    "            p = model(u,i)\n",
    "            ys_v.append(y.cpu()); ps_v.append(p.cpu())\n",
    "    y_val = torch.cat(ys_v); p_val = torch.cat(ps_v)\n",
    "    val_rmse = rmse(y_val, p_val)\n",
    "    val_r2   = r2_torch(y_val, p_val)\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"train RMSE: {train_rmse:.4f} | val RMSE: {val_rmse:.4f} | \"\n",
    "          f\"train R2: {train_r2:.4f} | val R2: {val_r2:.4f} | LR: {curr_lr:.2e}\")\n",
    "\n",
    "    if val_rmse + 1e-6 < best_val:\n",
    "        best_val = val_rmse; bad = 0\n",
    "        best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "model.to(device); model.eval()\n",
    "\n",
    "# ================== Predict test ==================\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for u,i in test_loader:\n",
    "        u,i = u.to(device), i.to(device)\n",
    "        p = model(u,i).cpu().numpy()\n",
    "        preds.append(p)\n",
    "pred = np.concatenate(preds, axis=0).reshape(-1)\n",
    "\n",
    "# clip về [min_r, max_r]\n",
    "pred = np.clip(pred, min_r, max_r)\n",
    "\n",
    "# fallback cho cold-start\n",
    "mask_cold = (~df_test['userid'].isin(seen_users)) | (~df_test['movieid'].isin(seen_items))\n",
    "if mask_cold.any():\n",
    "    pred[mask_cold.values] = global_mean\n",
    "\n",
    "# ================== Save \"Id,Score\" (Id bắt đầu từ 1) ==================\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": np.arange(1, len(df_test) + 1, dtype=int),\n",
    "    \"Score\": pred.astype(float)\n",
    "})\n",
    "submission.to_csv(SUB_PATH, index=False)\n",
    "print(f\"Saved to: {os.path.abspath(SUB_PATH)}\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1675974,
     "sourceId": 24064,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
