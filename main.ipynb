{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-28T13:31:58.146305Z",
     "iopub.status.busy": "2025-09-28T13:31:58.146031Z",
     "iopub.status.idle": "2025-09-28T13:32:00.684184Z",
     "shell.execute_reply": "2025-09-28T13:32:00.682927Z",
     "shell.execute_reply.started": "2025-09-28T13:31:58.146283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\sample.txt\n",
      "data\\test.txt\n",
      "data\\train.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:00.686873Z",
     "iopub.status.busy": "2025-09-28T13:32:00.686333Z",
     "iopub.status.idle": "2025-09-28T13:32:01.297474Z",
     "shell.execute_reply": "2025-09-28T13:32:01.296370Z",
     "shell.execute_reply.started": "2025-09-28T13:32:00.686839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  movieid  rating\n",
      "0       1        1       5\n",
      "1       1        2       3\n",
      "2       1        3       4\n",
      "3       1        4       3\n",
      "4       1        5       3\n",
      "userid     int64\n",
      "movieid    int64\n",
      "rating     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "path = \"data/train.txt\"  # đổi nếu cần\n",
    "\n",
    "rows = []\n",
    "with open(path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        nums = re.findall(r\"-?\\d+\", line)\n",
    "        if len(nums) >= 3:\n",
    "            rows.append([int(nums[0]), int(nums[1]), int(nums[2])])\n",
    "\n",
    "df_train = pd.DataFrame(rows, columns=[\"userid\", \"movieid\", \"rating\"])\n",
    "print(df_train.head())\n",
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:01.298851Z",
     "iopub.status.busy": "2025-09-28T13:32:01.298568Z",
     "iopub.status.idle": "2025-09-28T13:32:01.462878Z",
     "shell.execute_reply": "2025-09-28T13:32:01.461224Z",
     "shell.execute_reply.started": "2025-09-28T13:32:01.298827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  movieid\n",
      "0       1       20\n",
      "1       1       33\n",
      "2       1       61\n",
      "3       1      117\n",
      "4       1      155\n",
      "userid     int64\n",
      "movieid    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "path = \"data/test.txt\"  # đổi nếu cần\n",
    "\n",
    "rows = []\n",
    "with open(path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        nums = re.findall(r\"-?\\d+\", line)\n",
    "        if len(nums) >= 2:\n",
    "            rows.append([int(nums[0]), int(nums[1])])\n",
    "\n",
    "df_test = pd.DataFrame(rows, columns=[\"userid\", \"movieid\"])\n",
    "print(df_test.head())\n",
    "print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:01.464931Z",
     "iopub.status.busy": "2025-09-28T13:32:01.463917Z",
     "iopub.status.idle": "2025-09-28T13:32:07.231655Z",
     "shell.execute_reply": "2025-09-28T13:32:07.230523Z",
     "shell.execute_reply.started": "2025-09-28T13:32:01.464899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from typing import Sequence, List\n",
    "class NeuMF(nn.Module):\n",
    "    \"\"\"\n",
    "    NeuMF với one-hot embedding:\n",
    "      - User/Item -> one-hot (cố định) -> Linear chiếu sang latent (thay cho nn.Embedding)\n",
    "      - Nhánh GMF: element-wise product giữa 2 latent vector\n",
    "      - Nhánh MLP: concat 2 latent, qua nhiều Dense + ReLU (+ Dropout)\n",
    "      - Fusion: concat(GMF, MLP) -> Dropout -> (Dropout head) -> Linear(…, 1)\n",
    "\n",
    "    Tham số dropout:\n",
    "      - dropout_proj  : dropout ngay sau chiếu one-hot -> latent (cả GMF và MLP)\n",
    "      - dropout_hidden: dropout sau mỗi Dense của tháp MLP\n",
    "      - dropout_fusion: dropout sau khi concat GMF & MLP\n",
    "      - dropout_fc    : dropout ngay trước lớp Linear cuối cùng\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 k_gmf: int = 8,\n",
    "                 k_mlp: int = 32,\n",
    "                 mlp_layers=(64, 32, 16),\n",
    "                 dropout_hidden: float = 0.3,\n",
    "                 dropout_proj: float = 0.1,\n",
    "                 dropout_fusion: float = 0.2,\n",
    "                 dropout_fc: float = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # One-hot \"embeddings\": identity, freeze để dùng như one-hot lookup\n",
    "        self.oh_user = nn.Embedding.from_pretrained(torch.eye(num_users), freeze=True)\n",
    "        self.oh_item = nn.Embedding.from_pretrained(torch.eye(num_items), freeze=True)\n",
    "\n",
    "        # Chiếu one-hot -> latent (thay cho nn.Embedding)\n",
    "        self.gmf_user_proj = nn.Linear(num_users, k_gmf, bias=False)\n",
    "        self.gmf_item_proj = nn.Linear(num_items, k_gmf, bias=False)\n",
    "        self.mlp_user_proj = nn.Linear(num_users, k_mlp, bias=False)\n",
    "        self.mlp_item_proj = nn.Linear(num_items, k_mlp, bias=False)\n",
    "\n",
    "        # Dropout sau projection\n",
    "        self.do_proj_gmf_u = nn.Dropout(dropout_proj)\n",
    "        self.do_proj_gmf_i = nn.Dropout(dropout_proj)\n",
    "        self.do_proj_mlp_u = nn.Dropout(dropout_proj)\n",
    "        self.do_proj_mlp_i = nn.Dropout(dropout_proj)\n",
    "\n",
    "        # Tháp MLP: (Linear -> ReLU -> Dropout) * len(mlp_layers)\n",
    "        mlp = []\n",
    "        in_dim = k_mlp * 2\n",
    "        for units in mlp_layers:\n",
    "            mlp += [\n",
    "                nn.Linear(in_dim, units),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_hidden),\n",
    "            ]\n",
    "            in_dim = units\n",
    "        self.mlp_layers = nn.Sequential(*mlp)\n",
    "\n",
    "        # Dropout sau khi concat(GMF, MLP)\n",
    "        self.do_fusion = nn.Dropout(dropout_fusion)\n",
    "\n",
    "        # Head: Dropout trước fc\n",
    "        fusion_dim = k_gmf + (mlp_layers[-1] if mlp_layers else k_mlp * 2)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dropout_fc),\n",
    "            nn.Linear(fusion_dim, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Xavier cho các Linear\n",
    "        for m in [self.gmf_user_proj, self.gmf_item_proj, self.mlp_user_proj, self.mlp_item_proj]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        for m in self.mlp_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        lin = self.head[1]  # Linear cuối\n",
    "        nn.init.xavier_uniform_(lin.weight)\n",
    "        nn.init.zeros_(lin.bias)\n",
    "\n",
    "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        users: LongTensor shape (B,)\n",
    "        items: LongTensor shape (B,)\n",
    "        return: FloatTensor shape (B,)  — điểm số (rating dự đoán)\n",
    "        \"\"\"\n",
    "        # One-hot vectors (0/1)\n",
    "        u_oh = self.oh_user(users)   # (B, num_users)\n",
    "        i_oh = self.oh_item(items)   # (B, num_items)\n",
    "\n",
    "        # ----- GMF path -----\n",
    "        gu = self.gmf_user_proj(u_oh)      # (B, k_gmf)\n",
    "        gi = self.gmf_item_proj(i_oh)      # (B, k_gmf)\n",
    "        gu = self.do_proj_gmf_u(gu)\n",
    "        gi = self.do_proj_gmf_i(gi)\n",
    "        gmf = gu * gi                      # element-wise\n",
    "\n",
    "        # ----- MLP path -----\n",
    "        mu = self.mlp_user_proj(u_oh)      # (B, k_mlp)\n",
    "        mi = self.mlp_item_proj(i_oh)      # (B, k_mlp)\n",
    "        mu = self.do_proj_mlp_u(mu)\n",
    "        mi = self.do_proj_mlp_i(mi)\n",
    "        x = torch.cat([mu, mi], dim=-1)    # (B, 2*k_mlp)\n",
    "        x = self.mlp_layers(x)\n",
    "\n",
    "        # ----- Fusion + head -----\n",
    "        z = torch.cat([gmf, x], dim=-1)\n",
    "        z = self.do_fusion(z)\n",
    "        score = self.head(z).squeeze(-1)   # (B,)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:07.233163Z",
     "iopub.status.busy": "2025-09-28T13:32:07.232734Z",
     "iopub.status.idle": "2025-09-28T13:32:07.246490Z",
     "shell.execute_reply": "2025-09-28T13:32:07.245356Z",
     "shell.execute_reply.started": "2025-09-28T13:32:07.233139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from typing import Sequence, List\n",
    "\n",
    "class DMF(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Matrix Factorization (học trực tiếp A):\n",
    "      - A: (num_users, num_items) là tham số học được.\n",
    "      - forward(users, items):\n",
    "          + user vector = A[u, :]  (1 hàng)\n",
    "          + item vector = A[:, v]  (1 cột)\n",
    "          + qua MLP riêng -> L2-normalize -> cosine -> map [1,5]\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 d1: int = 64,                    # (không dùng ở bản này)\n",
    "                 hidden: Sequence[int] = (64, 32, 16),\n",
    "                 dropout: float = 0.2,\n",
    "                 use_bn: bool = False):\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "\n",
    "        # Ma trận A học trực tiếp (khởi tạo nhỏ quanh 0 để điểm ~3 sau khi map)\n",
    "        self.A = nn.Parameter(torch.randn(num_users, num_items) * 0.01)\n",
    "\n",
    "        # Tower MLP: user nhận vectơ kích thước num_items; item nhận vectơ kích thước num_users\n",
    "        def make_mlp(in_dim):\n",
    "            layers = []\n",
    "            last = in_dim\n",
    "            for h in hidden:\n",
    "                layers += [nn.Linear(last, h)]\n",
    "                if use_bn:\n",
    "                    layers += [nn.BatchNorm1d(h)]\n",
    "                layers += [nn.ReLU(inplace=True), nn.Dropout(dropout)]\n",
    "                last = h\n",
    "            return nn.Sequential(*layers), last\n",
    "\n",
    "        self.user_mlp, Du = make_mlp(num_items)\n",
    "        self.item_mlp, Dv = make_mlp(num_users)\n",
    "        assert Du == Dv, \"Hai tower phải có cùng output dim để tính cosine.\"\n",
    "        self.out_dim = Du\n",
    "        self.head = nn.Linear(self.out_dim * 2, 1)   # học cách ghép pu & qv -> score\n",
    "        nn.init.xavier_uniform_(self.head.weight)\n",
    "        nn.init.zeros_(self.head.bias)\n",
    "        # Khởi tạo tuyến tính\n",
    "        for m in list(self.user_mlp.modules()) + list(self.item_mlp.modules()):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    # --------------------------- forward (giống Neu) ---------------------------\n",
    "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        users/items: LongTensor (B,)\n",
    "        return: FloatTensor (B,) in [1, 5]\n",
    "        \"\"\"\n",
    "        # Lấy hàng/cột từ A\n",
    "        rows = self.A[users, :]                   # (B, num_items)\n",
    "        cols = self.A[:, items].transpose(0, 1)   # (B, num_users)\n",
    "    \n",
    "        # Qua MLP hai nhánh\n",
    "        pu = self.user_mlp(rows) if len(self.user_mlp) else rows   # (B, D)\n",
    "        qv = self.item_mlp(cols) if len(self.item_mlp) else cols   # (B, D)\n",
    "    \n",
    "        # (tuỳ chọn) normalize nhẹ, có thể bỏ nếu muốn để Linear tự học\n",
    "        # pu = F.normalize(pu, p=2, dim=-1)\n",
    "        # qv = F.normalize(qv, p=2, dim=-1)\n",
    "    \n",
    "        # Ghép và cho qua Linear head\n",
    "        z = torch.cat([pu, qv], dim=-1)           # (B, 2D)\n",
    "        s = self.head(z).squeeze(-1)              # (B,)\n",
    "    \n",
    "        # Ràng buộc đầu ra về [1, 5] bằng sigmoid thay vì clamp\n",
    "        \n",
    "        return s\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:32:07.247914Z",
     "iopub.status.busy": "2025-09-28T13:32:07.247584Z",
     "iopub.status.idle": "2025-09-28T13:32:07.282244Z",
     "shell.execute_reply": "2025-09-28T13:32:07.280962Z",
     "shell.execute_reply.started": "2025-09-28T13:32:07.247890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Sequence, Tuple\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    LightGCN tối giản cho implicit CF.\n",
    "    - E^(0) = concat([E_user, E_item]) với shape [(M+N), d] (user trước, item sau).\n",
    "    - Propagation: E^(k+1) = A_tilde @ E^(k), A_tilde = D^{-1/2} A D^{-1/2}.\n",
    "    - Layer-combine: E_final = sum_{k=0..K} alpha_k * E^(k), mặc định alpha_k = 1/(K+1).\n",
    "    - Score(u,i) = <e_u, e_i>.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        embedding_dim: int = 64,\n",
    "        num_layers: int = 3,\n",
    "        edges: Optional[torch.LongTensor] = None,   # shape [2, E], (user_id, item_id)\n",
    "        alpha: Optional[torch.Tensor] = None,       # (K+1,), nếu None -> uniform\n",
    "        device: Optional[torch.device] = None,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # E^(0): embedding riêng user & item\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "\n",
    "        # Alpha cho trộn tầng\n",
    "        no_edges = (edges is None) or (edges.numel() == 0)\n",
    "        if alpha is None:\n",
    "            if no_edges:\n",
    "                alpha = torch.zeros(num_layers + 1, dtype=dtype); alpha[0] = 1.0\n",
    "            else:\n",
    "                alpha = torch.full((num_layers + 1,), 1.0/(num_layers + 1), dtype=dtype)\n",
    "        else:\n",
    "            assert alpha.numel() == num_layers + 1, \"alpha phải có K+1 phần tử\"\n",
    "            alpha = alpha.to(dtype=dtype)\n",
    "        self.register_buffer(\"alpha\", alpha)\n",
    "\n",
    "        # A_tilde (sparse)\n",
    "        if no_edges:\n",
    "            num_nodes = num_users + num_items\n",
    "            A_tilde = torch.sparse_coo_tensor(\n",
    "                torch.zeros((2, 0), dtype=torch.long),\n",
    "                torch.tensor([], dtype=dtype),\n",
    "                (num_nodes, num_nodes),\n",
    "                device=device,\n",
    "                dtype=dtype\n",
    "            ).coalesce()\n",
    "        else:\n",
    "            A_tilde = self._build_norm_adj(edges, device=device, dtype=dtype)\n",
    "\n",
    "        # Lưu buffer chỉ số & giá trị để tái tạo nhanh mỗi lần propagate\n",
    "        self.register_buffer(\"A_tilde_indices\", A_tilde.indices())\n",
    "        self.register_buffer(\"A_tilde_values\",  A_tilde.values())\n",
    "        self.A_tilde_size = A_tilde.size()\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _build_norm_adj(\n",
    "        self,\n",
    "        edges: torch.LongTensor,\n",
    "        device: Optional[torch.device],\n",
    "        dtype: torch.dtype,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Xây A_tilde = D^{-1/2} A D^{-1/2} cho đồ thị hai phía (vô hướng).\"\"\"\n",
    "        M, N = self.num_users, self.num_items\n",
    "        if device is None:\n",
    "            device = edges.device\n",
    "\n",
    "        u = edges[0].to(torch.long)               # [E]\n",
    "        i = (edges[1].to(torch.long) + M)         # shift item id: [E] trong [M, M+N)\n",
    "\n",
    "        # cạnh vô hướng: (u,i) & (i,u)\n",
    "        src = torch.cat([u, i])\n",
    "        dst = torch.cat([i, u])\n",
    "        indices = torch.stack([src, dst], dim=0)  # [2, 2E]\n",
    "        values = torch.ones(indices.size(1), dtype=dtype, device=device)\n",
    "        num_nodes = M + N\n",
    "\n",
    "        A = torch.sparse_coo_tensor(indices, values, (num_nodes, num_nodes),\n",
    "                                    device=device, dtype=dtype).coalesce()\n",
    "\n",
    "        deg = torch.sparse.sum(A, dim=1).to_dense().clamp(min=1.0)  # tránh 0\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        row, col = A.indices()\n",
    "        norm_vals = deg_inv_sqrt[row] * A.values() * deg_inv_sqrt[col]\n",
    "        return torch.sparse_coo_tensor(A.indices(), norm_vals, A.size(),\n",
    "                                       device=device, dtype=dtype).coalesce()\n",
    "\n",
    "    def _E0(self) -> torch.Tensor:\n",
    "        \"\"\"E^(0) = concat([E_user, E_item]) với shape [(M+N), d].\"\"\"\n",
    "        return torch.cat([self.user_emb.weight, self.item_emb.weight], dim=0)\n",
    "\n",
    "    def _propagate(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Lan truyền K bước và trộn tầng. Trả về (E_user_final, E_item_final).\"\"\"\n",
    "        E0 = self._E0()\n",
    "        Es = [E0]\n",
    "\n",
    "        if self.A_tilde_values.numel() > 0:\n",
    "            A_tilde = torch.sparse_coo_tensor(\n",
    "                self.A_tilde_indices, self.A_tilde_values, self.A_tilde_size,\n",
    "                device=E0.device, dtype=E0.dtype\n",
    "            )\n",
    "            Ek = E0\n",
    "            for _ in range(self.num_layers):\n",
    "                Ek = torch.sparse.mm(A_tilde, Ek)\n",
    "                Es.append(Ek)\n",
    "        else:\n",
    "            # không cạnh → các tầng sau = 0, alpha[0]=1 ⇒ E_final = E0\n",
    "            for _ in range(self.num_layers):\n",
    "                Es.append(torch.zeros_like(E0))\n",
    "\n",
    "        E_final = torch.zeros_like(E0)\n",
    "        for k, Ek in enumerate(Es):\n",
    "            E_final = E_final + self.alpha[k] * Ek\n",
    "\n",
    "        return E_final[: self.num_users], E_final[self.num_users :]\n",
    "\n",
    "    # ---------- public API ----------\n",
    "    @torch.no_grad()\n",
    "    def get_all_embeddings(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Trả về (E_user_final [M,d], E_item_final [N,d]).\"\"\"\n",
    "        return self._propagate()\n",
    "\n",
    "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        users, items: LongTensor [B]\n",
    "        Trả về: scores [B] = <e_u, e_i>\n",
    "        \"\"\"\n",
    "        U, I = self._propagate()\n",
    "        eu = U[users]            # [B, d]\n",
    "        ei = I[items]            # [B, d]\n",
    "        return (eu * ei).sum(dim=1)\n",
    "\n",
    "    def bpr_loss(\n",
    "        self,\n",
    "        users: torch.Tensor,\n",
    "        pos_items: torch.Tensor,\n",
    "        neg_items: torch.Tensor,\n",
    "        l2_reg: float = 1e-4,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Pairwise BPR loss; regularize chỉ E^(0) như LightGCN gốc.\n",
    "        users, pos_items, neg_items: LongTensor [B]\n",
    "        \"\"\"\n",
    "        U, I = self._propagate()\n",
    "        eu = U[users]\n",
    "        ei = I[pos_items]\n",
    "        ej = I[neg_items]\n",
    "        y_pos = (eu * ei).sum(dim=1)\n",
    "        y_neg = (eu * ej).sum(dim=1)\n",
    "        loss = -torch.nn.functional.logsigmoid(y_pos - y_neg).mean()\n",
    "\n",
    "        # L2 chỉ trên E^(0)\n",
    "        reg = (\n",
    "            self.user_emb.weight.norm(p=2).pow(2)\n",
    "            + self.item_emb.weight.norm(p=2).pow(2)\n",
    "        ) / (self.num_users + self.num_items)\n",
    "\n",
    "        return loss + l2_reg * reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T13:33:24.114627Z",
     "iopub.status.busy": "2025-09-28T13:33:24.113221Z",
     "iopub.status.idle": "2025-09-28T13:33:32.275478Z",
     "shell.execute_reply": "2025-09-28T13:33:32.273918Z",
     "shell.execute_reply.started": "2025-09-28T13:33:24.114590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.79it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train RMSE: 1.3811 | val RMSE: 1.3949 | train R2: -0.5043 | val R2: -0.5342 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.62it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train RMSE: 1.1897 | val RMSE: 1.2226 | train R2: -0.1162 | val R2: -0.1786 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.63it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train RMSE: 1.0869 | val RMSE: 1.1281 | train R2: 0.0683 | val R2: -0.0035 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.19it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train RMSE: 1.0254 | val RMSE: 1.0703 | train R2: 0.1707 | val R2: 0.0967 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.45it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train RMSE: 0.9858 | val RMSE: 1.0333 | train R2: 0.2336 | val R2: 0.1581 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.84it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train RMSE: 0.9566 | val RMSE: 1.0069 | train R2: 0.2782 | val R2: 0.2005 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.33it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train RMSE: 0.9338 | val RMSE: 0.9852 | train R2: 0.3123 | val R2: 0.2347 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:11<00:00,  5.99it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train RMSE: 0.9173 | val RMSE: 0.9709 | train R2: 0.3364 | val R2: 0.2567 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.80it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train RMSE: 0.9040 | val RMSE: 0.9618 | train R2: 0.3556 | val R2: 0.2705 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  8.94it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train RMSE: 0.8915 | val RMSE: 0.9525 | train R2: 0.3732 | val R2: 0.2846 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.22it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train RMSE: 0.8811 | val RMSE: 0.9470 | train R2: 0.3878 | val R2: 0.2928 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.57it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train RMSE: 0.8705 | val RMSE: 0.9401 | train R2: 0.4024 | val R2: 0.3032 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.51it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train RMSE: 0.8608 | val RMSE: 0.9363 | train R2: 0.4156 | val R2: 0.3088 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train RMSE: 0.8528 | val RMSE: 0.9324 | train R2: 0.4264 | val R2: 0.3145 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.59it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train RMSE: 0.8435 | val RMSE: 0.9281 | train R2: 0.4388 | val R2: 0.3208 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.45it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train RMSE: 0.8316 | val RMSE: 0.9218 | train R2: 0.4546 | val R2: 0.3300 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.50it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train RMSE: 0.8202 | val RMSE: 0.9182 | train R2: 0.4694 | val R2: 0.3351 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.82it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train RMSE: 0.8075 | val RMSE: 0.9146 | train R2: 0.4857 | val R2: 0.3404 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.78it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train RMSE: 0.7941 | val RMSE: 0.9111 | train R2: 0.5027 | val R2: 0.3455 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.61it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train RMSE: 0.7804 | val RMSE: 0.9081 | train R2: 0.5197 | val R2: 0.3498 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.50it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | train RMSE: 0.7647 | val RMSE: 0.9053 | train R2: 0.5388 | val R2: 0.3538 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.83it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | train RMSE: 0.7493 | val RMSE: 0.9020 | train R2: 0.5573 | val R2: 0.3584 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.61it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | train RMSE: 0.7341 | val RMSE: 0.9026 | train R2: 0.5750 | val R2: 0.3576 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.42it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | train RMSE: 0.7157 | val RMSE: 0.9002 | train R2: 0.5960 | val R2: 0.3610 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.39it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | train RMSE: 0.6970 | val RMSE: 0.8977 | train R2: 0.6169 | val R2: 0.3646 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | train RMSE: 0.6769 | val RMSE: 0.8962 | train R2: 0.6386 | val R2: 0.3666 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.85it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | train RMSE: 0.6571 | val RMSE: 0.8967 | train R2: 0.6595 | val R2: 0.3660 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.66it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | train RMSE: 0.6351 | val RMSE: 0.8968 | train R2: 0.6819 | val R2: 0.3659 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.50it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | train RMSE: 0.6138 | val RMSE: 0.8980 | train R2: 0.7029 | val R2: 0.3642 | LR: 1.00e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.93it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | train RMSE: 0.5906 | val RMSE: 0.8981 | train R2: 0.7249 | val R2: 0.3640 | LR: 5.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.33it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | train RMSE: 0.5758 | val RMSE: 0.8959 | train R2: 0.7385 | val R2: 0.3671 | LR: 5.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.49it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | train RMSE: 0.5639 | val RMSE: 0.8971 | train R2: 0.7492 | val R2: 0.3654 | LR: 5.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.10it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | train RMSE: 0.5527 | val RMSE: 0.8982 | train R2: 0.7591 | val R2: 0.3639 | LR: 5.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:11<00:00,  6.11it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | train RMSE: 0.5413 | val RMSE: 0.8996 | train R2: 0.7689 | val R2: 0.3619 | LR: 5.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:11<00:00,  6.10it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | train RMSE: 0.5304 | val RMSE: 0.8999 | train R2: 0.7781 | val R2: 0.3615 | LR: 2.50e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:09<00:00,  7.17it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | train RMSE: 0.5237 | val RMSE: 0.9006 | train R2: 0.7837 | val R2: 0.3604 | LR: 2.50e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.83it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | train RMSE: 0.5180 | val RMSE: 0.9011 | train R2: 0.7884 | val R2: 0.3597 | LR: 2.50e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  8.94it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | train RMSE: 0.5125 | val RMSE: 0.9027 | train R2: 0.7929 | val R2: 0.3575 | LR: 2.50e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  8.92it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | train RMSE: 0.5069 | val RMSE: 0.9032 | train R2: 0.7974 | val R2: 0.3567 | LR: 1.25e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.81it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | train RMSE: 0.5038 | val RMSE: 0.9032 | train R2: 0.7998 | val R2: 0.3567 | LR: 1.25e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.56it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | train RMSE: 0.5009 | val RMSE: 0.9040 | train R2: 0.8022 | val R2: 0.3555 | LR: 1.25e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.15it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | train RMSE: 0.4980 | val RMSE: 0.9044 | train R2: 0.8044 | val R2: 0.3551 | LR: 1.25e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.82it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | train RMSE: 0.4951 | val RMSE: 0.9048 | train R2: 0.8067 | val R2: 0.3545 | LR: 6.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.64it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | train RMSE: 0.4936 | val RMSE: 0.9049 | train R2: 0.8078 | val R2: 0.3543 | LR: 6.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.43it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | train RMSE: 0.4922 | val RMSE: 0.9051 | train R2: 0.8090 | val R2: 0.3541 | LR: 6.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.81it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | train RMSE: 0.4907 | val RMSE: 0.9054 | train R2: 0.8101 | val R2: 0.3536 | LR: 6.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.82it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | train RMSE: 0.4893 | val RMSE: 0.9056 | train R2: 0.8112 | val R2: 0.3533 | LR: 3.13e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.78it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | train RMSE: 0.4885 | val RMSE: 0.9058 | train R2: 0.8118 | val R2: 0.3531 | LR: 3.13e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:08<00:00,  8.72it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | train RMSE: 0.4877 | val RMSE: 0.9059 | train R2: 0.8124 | val R2: 0.3529 | LR: 3.13e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  9.03it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | train RMSE: 0.4870 | val RMSE: 0.9061 | train R2: 0.8130 | val R2: 0.3527 | LR: 3.13e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:07<00:00,  8.97it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | train RMSE: 0.4862 | val RMSE: 0.9061 | train R2: 0.8135 | val R2: 0.3526 | LR: 1.56e-04\n",
      "Early stopping.\n",
      "Saved to: e:\\Sao lưu onedrive\\not de ra truong nao\\Hệ gợi ý\\Project_RS_in_HUST\\output\\submission.csv\n",
      "   Id     Score\n",
      "0   1  3.898017\n",
      "1   2  3.646442\n",
      "2   3  4.296011\n",
      "3   4  4.007053\n",
      "4   5  2.027400\n"
     ]
    }
   ],
   "source": [
    "# NeuMF in PyTorch: GMF + MLP for rating regression + AdamW + LR scheduler + save \"Id,Score\"\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split   # <-- thêm import\n",
    "\n",
    "# ================== Hyperparams & configs ==================\n",
    "SEED = 42\n",
    "SUB_PATH   = \"output/submission.csv\"\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = 'cpu'\n",
    "K_GMF = 8\n",
    "K_MLP = 32\n",
    "MLP_LAYERS = (32, 16, 8)\n",
    "DROPOUT = 0.4\n",
    "LR = 1e-2\n",
    "EPOCHS = 100\n",
    "BATCH_TRAIN = 1024\n",
    "BATCH_TEST  = 1024\n",
    "VAL_RATIO = 0.2\n",
    "PATIENCE = 20\n",
    "WEIGHT_DECAY = 1e-4  # AdamW weight decay\n",
    "\n",
    "# ================== Assume df_train / df_test are ready ==================\n",
    "# df_train: userid,movieid,rating ; df_test: userid,movieid\n",
    "\n",
    "# ---- mapping ID -> index liên tục (từ cả train + test) ----\n",
    "all_users = pd.Index(pd.concat([df_train['userid'], df_test['userid']]).unique())\n",
    "all_items = pd.Index(pd.concat([df_train['movieid'], df_test['movieid']]).unique())\n",
    "user2idx = {u:i for i,u in enumerate(all_users)}\n",
    "item2idx = {m:i for i,m in enumerate(all_items)}\n",
    "num_users = len(user2idx); num_items = len(item2idx)\n",
    "\n",
    "df_train_idx = df_train.assign(\n",
    "    user_idx = df_train['userid'].map(user2idx).astype('int64'),\n",
    "    item_idx = df_train['movieid'].map(item2idx).astype('int64')\n",
    ")\n",
    "df_test_idx = df_test.assign(\n",
    "    user_idx = df_test['userid'].map(user2idx).astype('int64'),\n",
    "    item_idx = df_test['movieid'].map(item2idx).astype('int64')\n",
    ")\n",
    "\n",
    "min_r = float(df_train['rating'].min())\n",
    "max_r = float(df_train['rating'].max())\n",
    "global_mean = float(df_train['rating'].mean())\n",
    "seen_users = set(df_train['userid'].unique())\n",
    "seen_items = set(df_train['movieid'].unique())\n",
    "\n",
    "# ================== Dataset / DataLoader ==================\n",
    "class RatingsDS(Dataset):\n",
    "    def __init__(self, u, i, y=None):\n",
    "        self.u = torch.as_tensor(u, dtype=torch.long)\n",
    "        self.i = torch.as_tensor(i, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.as_tensor(y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.u)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.u[idx], self.i[idx]\n",
    "        return self.u[idx], self.i[idx], self.y[idx]\n",
    "\n",
    "train_full = RatingsDS(\n",
    "    df_train_idx['user_idx'].values,\n",
    "    df_train_idx['item_idx'].values,\n",
    "    df_train_idx['rating'].values,\n",
    ")\n",
    "\n",
    "all_idx = np.arange(len(df_train_idx))\n",
    "train_idx, val_idx = train_test_split(\n",
    "    all_idx,\n",
    "    test_size=VAL_RATIO,\n",
    "    random_state=SEED,\n",
    "    stratify=df_train_idx['rating']\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_ds = Subset(train_full, train_idx)\n",
    "val_ds   = Subset(train_full, val_idx)\n",
    "\n",
    "test_ds  = RatingsDS(df_test_idx['user_idx'].values, df_test_idx['item_idx'].values)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds, batch_size=max(512, BATCH_TRAIN), shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_TEST, shuffle=False)\n",
    "\n",
    "# ================== Model ==================\n",
    "df_tr = df_train.copy()\n",
    "\n",
    "# Nếu có rating và muốn lấy positive theo ngưỡng:\n",
    "if 'rating' in df_tr.columns:\n",
    "    df_tr = df_tr[df_tr['rating'] >= 3.0]   # hoặc >= 3.5, tuỳ bài\n",
    "\n",
    "# Map sang chỉ số liên tục\n",
    "df_tr['user_idx'] = df_tr['userid'].map(user2idx).astype('int64')\n",
    "df_tr['item_idx'] = df_tr['movieid'].map(item2idx).astype('int64')\n",
    "\n",
    "# Mỗi (user,item) một cạnh (LightGCN không cần multiple-edges)\n",
    "df_tr = df_tr.drop_duplicates(subset=['user_idx', 'item_idx'])\n",
    "\n",
    "u = torch.as_tensor(df_tr['user_idx'].values, dtype=torch.long)\n",
    "i = torch.as_tensor(df_tr['item_idx'].values, dtype=torch.long)\n",
    "edges = torch.stack([u, i], dim=0).to(device)   # shape [2, E]\n",
    "\n",
    "\n",
    "model = NeuMF(num_users, num_items, K_GMF, K_MLP, MLP_LAYERS, DROPOUT).to(device)\n",
    "# model = DMF(num_users, num_items, d1=64, hidden=(64,32), dropout=0.3, use_bn=True).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "# model = LightGCN(num_users, num_items, embedding_dim=64, num_layers=3, edges=edges.to(device)).to(device)\n",
    "# ================== Train ==================\n",
    "device = next(model.parameters()).device\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-6\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(((y_true - y_pred) ** 2).mean().item())\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def r2_torch(y_true: torch.Tensor, y_pred: torch.Tensor) -> float:\n",
    "    \"\"\"R^2 dùng sklearn.\"\"\"\n",
    "    return r2_score(y_true.detach().cpu().numpy(),\n",
    "                    y_pred.detach().cpu().numpy())\n",
    "\n",
    "best_val = float(\"inf\"); patience = PATIENCE; bad = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ----- train -----\n",
    "    model.train()\n",
    "    for u,i,y in tqdm(train_loader):\n",
    "        u,i,y = u.to(device), i.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        p = model(u,i)\n",
    "        loss = criterion(p, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ----- evaluate train -----\n",
    "    model.eval()\n",
    "    ys_tr, ps_tr = [], []\n",
    "    with torch.no_grad():\n",
    "        for u,i,y in train_loader:\n",
    "            u,i,y = u.to(device), i.to(device), y.to(device)\n",
    "            p = model(u,i)\n",
    "            ys_tr.append(y.cpu()); ps_tr.append(p.cpu())\n",
    "    y_tr = torch.cat(ys_tr); p_tr = torch.cat(ps_tr)\n",
    "    train_rmse = rmse(y_tr, p_tr)\n",
    "    train_r2   = r2_torch(y_tr, p_tr)\n",
    "\n",
    "    # ----- validate -----\n",
    "    ys_v, ps_v = [], []\n",
    "    with torch.no_grad():\n",
    "        for u,i,y in tqdm(val_loader):\n",
    "            u,i,y = u.to(device), i.to(device), y.to(device)\n",
    "            p = model(u,i)\n",
    "            ys_v.append(y.cpu()); ps_v.append(p.cpu())\n",
    "    y_val = torch.cat(ys_v); p_val = torch.cat(ps_v)\n",
    "    val_rmse = rmse(y_val, p_val)\n",
    "    val_r2   = r2_torch(y_val, p_val)\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"train RMSE: {train_rmse:.4f} | val RMSE: {val_rmse:.4f} | \"\n",
    "          f\"train R2: {train_r2:.4f} | val R2: {val_r2:.4f} | LR: {curr_lr:.2e}\")\n",
    "\n",
    "    if val_rmse + 1e-6 < best_val:\n",
    "        best_val = val_rmse; bad = 0\n",
    "        best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "model.to(device); model.eval()\n",
    "\n",
    "# ================== Predict test ==================\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for u,i in test_loader:\n",
    "        u,i = u.to(device), i.to(device)\n",
    "        p = model(u,i).cpu().numpy()\n",
    "        preds.append(p)\n",
    "pred = np.concatenate(preds, axis=0).reshape(-1)\n",
    "\n",
    "# clip về [min_r, max_r]\n",
    "pred = np.clip(pred, min_r, max_r)\n",
    "\n",
    "# fallback cho cold-start\n",
    "mask_cold = (~df_test['userid'].isin(seen_users)) | (~df_test['movieid'].isin(seen_items))\n",
    "if mask_cold.any():\n",
    "    pred[mask_cold.values] = global_mean\n",
    "\n",
    "# ================== Save \"Id,Score\" (Id bắt đầu từ 1) ==================\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": np.arange(1, len(df_test) + 1, dtype=int),\n",
    "    \"Score\": pred.astype(float)\n",
    "})\n",
    "submission.to_csv(SUB_PATH, index=False)\n",
    "print(f\"Saved to: {os.path.abspath(SUB_PATH)}\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1675974,
     "sourceId": 24064,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
